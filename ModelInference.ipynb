{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.672147Z",
     "start_time": "2025-11-13T10:58:34.657998Z"
    }
   },
   "cell_type": "code",
   "source": "# # Model Save and Reload\n",
   "id": "637ebba7f7f77d09",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.687380Z",
     "start_time": "2025-11-13T10:58:34.675252Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 1. Import Libraries\n",
   "id": "7c796bdf7b284cc1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.702768Z",
     "start_time": "2025-11-13T10:58:34.689648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "import os\n"
   ],
   "id": "78ca46ec7cb44e30",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.718165Z",
     "start_time": "2025-11-13T10:58:34.704944Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 2. Define Model Architectures\n",
   "id": "2c62bab4b3bbbd7b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.733353Z",
     "start_time": "2025-11-13T10:58:34.720233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_resnet50_classifier(num_classes=23):\n",
    "    \"\"\"Build ResNet50 model architecture\"\"\"\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def build_efficientnet_classifier(num_classes=23):\n",
    "    \"\"\"Build EfficientNet-B0 model architecture\"\"\"\n",
    "    model = models.efficientnet_b0(weights=None)\n",
    "    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    return model\n"
   ],
   "id": "bf8926f56afea307",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.749347Z",
     "start_time": "2025-11-13T10:58:34.735472Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 3. Save Model Function\n",
   "id": "eefc4cd7ea367ef5",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.764795Z",
     "start_time": "2025-11-13T10:58:34.751636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_model_with_metadata(model, history, model_name, num_classes, class_to_idx):\n",
    "    \"\"\"\n",
    "    Save model with complete metadata.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        history: Dictionary with training history (train_loss, train_acc, val_loss, val_acc)\n",
    "        model_name: Name of the model (e.g., 'resnet50', 'efficientnet_b0')\n",
    "        num_classes: Number of classes\n",
    "        class_to_idx: Dictionary mapping class names to indices\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'history': history,\n",
    "        'num_classes': num_classes,\n",
    "        'class_to_idx': class_to_idx,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "    filename = f'{model_name}_complete.pth'\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"✓ Saved {model_name} to '{filename}'\")\n",
    "\n",
    "# Example usage (from training notebook):\n",
    "# save_model_with_metadata(resnet_model, resnet_history, 'resnet50',\n",
    "#                          len(idx_to_class), class_to_idx)\n",
    "# save_model_with_metadata(efficientnet_model, efficientnet_history, 'efficientnet_b0',\n",
    "#                          len(idx_to_class), class_to_idx)\n"
   ],
   "id": "26f50699618f07be",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.779990Z",
     "start_time": "2025-11-13T10:58:34.766873Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 4. Load Model Function\n",
   "id": "2fcb39ad7c5383e1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.795551Z",
     "start_time": "2025-11-13T10:58:34.782065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(model_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Load a trained PyTorch model with backward compatibility.\n",
    "\n",
    "    Supports two formats:\n",
    "    1. Complete checkpoint (with metadata: model_state_dict, history, class_to_idx, etc.)\n",
    "    2. Legacy checkpoint (weights only: state_dict)\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the saved model checkpoint\n",
    "        device: Device to load the model on ('cpu' or 'cuda')\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, class_to_idx, idx_to_class)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "    # Check if it's a complete checkpoint or just weights\n",
    "    is_complete = isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint\n",
    "\n",
    "    if is_complete:\n",
    "        # ========== Complete checkpoint format ==========\n",
    "        print(\"→ Detected: Complete checkpoint (with metadata)\")\n",
    "\n",
    "        # Extract metadata\n",
    "        num_classes = checkpoint['num_classes']\n",
    "        model_name = checkpoint['model_name']\n",
    "        class_to_idx = checkpoint['class_to_idx']\n",
    "\n",
    "        # Build model architecture\n",
    "        if 'resnet' in model_name.lower():\n",
    "            model = build_resnet50_classifier(num_classes)\n",
    "        elif 'efficientnet' in model_name.lower():\n",
    "            model = build_efficientnet_classifier(num_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_name}\")\n",
    "\n",
    "        # Load trained weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Create idx_to_class mapping\n",
    "        idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "        print(f\"✓ Loaded {model_name} with {num_classes} classes\")\n",
    "\n",
    "    else:\n",
    "        # ========== Legacy checkpoint format (weights only) ==========\n",
    "        print(\"→ Detected: Legacy checkpoint (weights only)\")\n",
    "\n",
    "        # Infer num_classes from the weights\n",
    "        if 'fc.weight' in checkpoint:  # ResNet50\n",
    "            num_classes = checkpoint['fc.weight'].shape[0]\n",
    "            model_type = 'resnet50'\n",
    "            print(f\"→ Detected model type: ResNet50\")\n",
    "        elif 'classifier.1.weight' in checkpoint:  # EfficientNet\n",
    "            num_classes = checkpoint['classifier.1.weight'].shape[0]\n",
    "            model_type = 'efficientnet'\n",
    "            print(f\"→ Detected model type: EfficientNet-B0\")\n",
    "        else:\n",
    "            raise ValueError(\"Cannot determine model type from checkpoint keys\")\n",
    "\n",
    "        # Build model architecture\n",
    "        if model_type == 'resnet50':\n",
    "            model = build_resnet50_classifier(num_classes)\n",
    "        else:\n",
    "            model = build_efficientnet_classifier(num_classes)\n",
    "\n",
    "        # Load weights\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Reconstruct class mapping from CLEAN_DIR\n",
    "        print(f\"→ Reconstructing class mappings from dataset...\")\n",
    "        import torchvision\n",
    "\n",
    "        # Try to find CLEAN_DIR\n",
    "        ROOT = Path().resolve()\n",
    "        CLEAN_DIR = os.path.join(ROOT, \"data\", \"clean\")\n",
    "\n",
    "        if os.path.exists(CLEAN_DIR):\n",
    "            clean_dataset = torchvision.datasets.ImageFolder(root=CLEAN_DIR)\n",
    "            class_to_idx = clean_dataset.class_to_idx\n",
    "            idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "            print(f\"✓ Reconstructed class mappings from {CLEAN_DIR}\")\n",
    "        else:\n",
    "            print(f\"⚠ Warning: {CLEAN_DIR} not found\")\n",
    "            print(f\"→ Creating placeholder class mappings (0-{num_classes-1})\")\n",
    "            class_to_idx = {f\"class_{i}\": i for i in range(num_classes)}\n",
    "            idx_to_class = {i: f\"class_{i}\" for i in range(num_classes)}\n",
    "\n",
    "        print(f\"✓ Loaded legacy checkpoint with {num_classes} classes\")\n",
    "\n",
    "    return model, class_to_idx, idx_to_class\n"
   ],
   "id": "74fc683de6c8de2b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:34.810740Z",
     "start_time": "2025-11-13T10:58:34.797618Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 5. Load Models\n",
   "id": "b312620b69cbdaa2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:35.242322Z",
     "start_time": "2025-11-13T10:58:34.813802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model paths\n",
    "ROOT = Path().resolve()\n",
    "RESNET_MODEL_PATH = os.path.join(ROOT, \"best_resnet50.pth\")\n",
    "EFFICIENTNET_MODEL_PATH = os.path.join(ROOT, \"best_efficientnet_b0.pth\")\n",
    "\n",
    "# Load models\n",
    "print(\"\\nLoading ResNet50...\")\n",
    "resnet_model, resnet_class_to_idx, resnet_idx_to_class = load_model(RESNET_MODEL_PATH, device)\n",
    "\n",
    "print(\"\\nLoading EfficientNet-B0...\")\n",
    "efficientnet_model, efficientnet_class_to_idx, efficientnet_idx_to_class = load_model(EFFICIENTNET_MODEL_PATH, device)\n",
    "\n",
    "print(\"\\n✓ All models loaded successfully!\")\n"
   ],
   "id": "911028bb888c6cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Loading ResNet50...\n",
      "Loading model from: Q:\\Users\\zgl-7\\Source\\Repos\\DS3000-25fall\\best_resnet50.pth\n",
      "→ Detected: Legacy checkpoint (weights only)\n",
      "→ Detected model type: ResNet50\n",
      "→ Reconstructing class mappings from dataset...\n",
      "✓ Reconstructed class mappings from Q:\\Users\\zgl-7\\Source\\Repos\\DS3000-25fall\\data\\clean\n",
      "✓ Loaded legacy checkpoint with 23 classes\n",
      "\n",
      "Loading EfficientNet-B0...\n",
      "Loading model from: Q:\\Users\\zgl-7\\Source\\Repos\\DS3000-25fall\\best_efficientnet_b0.pth\n",
      "→ Detected: Legacy checkpoint (weights only)\n",
      "→ Detected model type: EfficientNet-B0\n",
      "→ Reconstructing class mappings from dataset...\n",
      "✓ Reconstructed class mappings from Q:\\Users\\zgl-7\\Source\\Repos\\DS3000-25fall\\data\\clean\n",
      "✓ Loaded legacy checkpoint with 23 classes\n",
      "\n",
      "✓ All models loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:35.257985Z",
     "start_time": "2025-11-13T10:58:35.245643Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 6. Inference Setup\n",
   "id": "6b75fa3843c080ac",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:35.273168Z",
     "start_time": "2025-11-13T10:58:35.261070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Image preprocessing\n",
    "IMG_SIZE = 224\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "inference_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "def predict_image(model, image_path, idx_to_class, device, top_k=5):\n",
    "    \"\"\"\n",
    "    Predict the class of an image.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        image_path: Path to the image file\n",
    "        idx_to_class: Dictionary mapping class indices to class names\n",
    "        device: Device to run inference on\n",
    "        top_k: Number of top predictions to return\n",
    "\n",
    "    Returns:\n",
    "        dict: Prediction results with top-k classes and probabilities\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = inference_transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        top_probs, top_indices = torch.topk(probabilities, top_k, dim=1)\n",
    "\n",
    "    # Convert to class names\n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        class_idx = top_indices[0][i].item()\n",
    "        prob = top_probs[0][i].item()\n",
    "        class_name = idx_to_class[class_idx]\n",
    "        results.append({\n",
    "            'rank': i + 1,\n",
    "            'class': class_name,\n",
    "            'probability': prob,\n",
    "            'confidence': f\"{prob * 100:.2f}%\"\n",
    "        })\n",
    "\n",
    "    return results, image\n",
    "\n",
    "print(\"✓ Inference functions ready!\")\n"
   ],
   "id": "d7dadd0b65d080aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Inference functions ready!\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:35.288363Z",
     "start_time": "2025-11-13T10:58:35.275237Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 7. Example Prediction\n",
   "id": "13435b9cc9c354b6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:35.303743Z",
     "start_time": "2025-11-13T10:58:35.290605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Predict on an image\n",
    "image_path = \"path/to/your/image.jpg\"  # Change this to your image path\n",
    "\n",
    "# Uncomment to use:\n",
    "# results, image = predict_image(resnet_model, image_path, resnet_idx_to_class, device, top_k=5)\n",
    "#\n",
    "# print(\"\\nTop 5 Predictions:\")\n",
    "# for pred in results:\n",
    "#     print(f\"{pred['rank']}. {pred['class']}: {pred['confidence']}\")\n"
   ],
   "id": "187abbd78a327d90",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:58:35.319293Z",
     "start_time": "2025-11-13T10:58:35.305855Z"
    }
   },
   "cell_type": "code",
   "source": "# ## 8. Export to HTML\n",
   "id": "4ea94828ac15987e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:00:38.616565Z",
     "start_time": "2025-11-13T10:58:35.321377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Export this notebook with outputs to HTML\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "notebook_name = \"ModelInference.ipynb\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_html = f\"ModelInference_output_{timestamp}.html\"\n",
    "\n",
    "try:\n",
    "    cmd = f'jupyter nbconvert --to html --execute \"{notebook_name}\" --output \"{output_html}\"'\n",
    "    print(f\"Exporting notebook to HTML...\")\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ Successfully exported to: {output_html}\")\n",
    "    else:\n",
    "        print(f\"Note: Export command available, run manually if needed\")\n",
    "        print(f\"Command: jupyter nbconvert --to html {notebook_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Manual export: File > Download as > HTML (.html)\")\n",
    "\n"
   ],
   "id": "5bde783cfa265224",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting notebook to HTML...\n",
      "✓ Successfully exported to: ModelInference_output_20251113_055835.html\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
