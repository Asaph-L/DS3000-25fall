{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Data import and device",
   "id": "24585a4184fa722c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ],
   "id": "39fe4041adf482df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- config ---\n",
    "ROOT = Path().resolve()\n",
    "DATA_DIR = os.path.join(ROOT, \"data\", \"archive\", \"Dataset\")\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "PIN = torch.cuda.is_available()\n",
    "\n",
    "# --- transforms ---\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(0.5),\n",
    "    T.RandomRotation(10),\n",
    "    T.ColorJitter(0.1, 0.1, 0.05),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "\n",
    "def get_loaders(\n",
    "        data_dir: str = DATA_DIR,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        val_split: float = VAL_SPLIT,\n",
    "        seed: int = SEED,\n",
    "        num_workers: int = NUM_WORKERS,\n",
    "        pin_memory: bool = PIN,\n",
    "):\n",
    "    full = torchvision.datasets.ImageFolder(root=data_dir, transform=train_tf)\n",
    "    n = len(full)\n",
    "    n_val = int(n * val_split)\n",
    "    n_train = n - n_val\n",
    "\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    train_set, val_set = random_split(full, [n_train, n_val], generator=g)\n",
    "\n",
    "    # clean tf for val\n",
    "    val_set.dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=val_tf)\n",
    "\n",
    "    class_to_idx = full.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=batch_size * 2, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n",
    "    )\n",
    "    return train_loader, val_loader, idx_to_class\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader, val_loader, idx_to_class = get_loaders()\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n"
   ],
   "id": "4b20f94a26663316"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.Data visualization",
   "id": "daab3b0145ff6914"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "show image amount, show class amount,and batch size",
   "id": "9f9235b9e47b2f51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Using device:\", device)\n",
    "print(f\"Total images: {len(train_loader.dataset) + len(val_loader.dataset)}  |  \"\n",
    "      f\"Train: {len(train_loader.dataset)}  Val: {len(val_loader.dataset)}\")\n",
    "print(\"Num classes:\", len(idx_to_class))\n",
    "print(\"Classes:\", list(idx_to_class.values()))\n",
    "print(\"Batch:\", xb.shape, yb.shape)\n"
   ],
   "id": "6aa487a9089e8ec1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Display the first 10 images from the dataset.",
   "id": "ea492d4839491ef2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = train_loader.dataset\n",
    "for i in range(9):\n",
    "    img, label = dataset[i]\n",
    "    # --- 反归一化 ---\n",
    "    img = img.detach().cpu()\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    if img.shape[0] == 3:\n",
    "        img = img * std + mean\n",
    "\n",
    "    # --- CHW -> HWC + 转成 0~255 uint8 ---\n",
    "    img = img.permute(1, 2, 0).clamp(0, 1)  # HWC, [0,1]\n",
    "    img = (img * 255).byte().numpy()  # uint8 array\n",
    "\n",
    "    # --- 转 PIL 图像并显示 ---\n",
    "    img = Image.fromarray(img)\n",
    "    display(img)\n",
    "\n",
    "    real_class_name = idx_to_class[label]\n",
    "    print(real_class_name, end=\"\")"
   ],
   "id": "6f4627cb3a1de005"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Count images per class to check class balance.",
   "id": "62ed81c7b0c92f06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "labels = []\n",
    "for img, label in dataset:\n",
    "    labels.append(idx_to_class[label])\n",
    "\n",
    "print(Counter(labels))"
   ],
   "id": "19ebd9b2dd29b791"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "count = Counter(labels)\n",
    "\n",
    "# 构造 DataFrame（关键在这里）\n",
    "df = pd.DataFrame(sorted(count.items(), key=lambda x: x[0]), columns=[\"class\", \"count\"])\n",
    "\n",
    "# 直接可视化（Jupyter里自动显示，不会卡）\n",
    "fig = px.bar(df, x=\"class\", y=\"count\", title=\"Class Distribution\", text=\"count\")\n",
    "fig.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "\n",
    "display(fig)"
   ],
   "id": "5ca710ef68bdda82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Data cleaning",
   "id": "1caaaf0e159993b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### 3. Data cleaning\n",
    "import shutil\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "CLEAN_DIR = os.path.join(ROOT, \"data\", \"clean\")  # 输出干净数据的镜像目录\n",
    "MIN_SIDE = 64  # 过小图片阈值（任一边 < MIN_SIDE 则剔除）\n",
    "ALLOW_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}  # 可自行增减\n",
    "DO_DEDUP = True  # 是否进行感知哈希去重\n",
    "DEDUPE_SCOPE = \"global\"  # \"class\" 仅类内去重, \"global\" 全局去重\n",
    "\n",
    "\n",
    "def _safe_ext(p: Path) -> str:\n",
    "    return p.suffix.lower()\n",
    "\n",
    "\n",
    "def _is_image_file(p: Path) -> bool:\n",
    "    return _safe_ext(p) in ALLOW_EXTS\n",
    "\n",
    "\n",
    "def _pil_open_rgb(path: str):\n",
    "    \"\"\"打开并转 RGB，返回 (img, w, h)。失败抛异常。\"\"\"\n",
    "    with Image.open(path) as im:\n",
    "        im.load()\n",
    "        im = im.convert(\"RGB\")\n",
    "        w, h = im.size\n",
    "    return im, w, h\n",
    "\n",
    "\n",
    "def _ahash(img: Image.Image, hash_size: int = 8) -> int:\n",
    "    \"\"\"简单 aHash：缩放灰度 -> 与均值比较 -> bit 布尔阵列 -> 整数\"\"\"\n",
    "    g = img.convert(\"L\").resize((hash_size, hash_size), Image.BILINEAR)\n",
    "    arr = np.asarray(g, dtype=np.float32)\n",
    "    mean = arr.mean()\n",
    "    bits = (arr >= mean).astype(np.uint8).ravel()\n",
    "    # 将 64bit 布尔转整数\n",
    "    h = 0\n",
    "    for b in bits:\n",
    "        h = (h << 1) | int(b)\n",
    "    return h\n",
    "\n",
    "\n",
    "def _iter_class_images(root_dir: str):\n",
    "    \"\"\"遍历 ImageFolder 结构：root/class_x/xxx.jpg -> 产出 (class_name, path)\"\"\"\n",
    "    root = Path(root_dir)\n",
    "    for cls_dir in sorted([d for d in root.iterdir() if d.is_dir()]):\n",
    "        cls = cls_dir.name\n",
    "        for p in cls_dir.rglob(\"*\"):\n",
    "            if p.is_file() and _is_image_file(p):\n",
    "                yield cls, p\n",
    "\n",
    "\n",
    "def scan_and_clean(\n",
    "        src_dir: str = DATA_DIR,\n",
    "        dst_dir: str = CLEAN_DIR,\n",
    "        min_side: int = MIN_SIDE,\n",
    "        do_dedup: bool = DO_DEDUP,\n",
    "        dedupe_scope: str = DEDUPE_SCOPE,\n",
    "):\n",
    "    \"\"\"\n",
    "    扫描 src_dir -> 清洗 -> 拷贝到 dst_dir。返回清洗统计与重复信息。\n",
    "    \"\"\"\n",
    "    # 清空/重建输出目录\n",
    "    if os.path.exists(dst_dir):\n",
    "        shutil.rmtree(dst_dir)\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    stats = {\n",
    "        \"total_found\": 0,\n",
    "        \"copied\": 0,\n",
    "        \"skipped_unreadable\": 0,\n",
    "        \"skipped_too_small\": 0,\n",
    "        \"skipped_other\": 0,\n",
    "        \"by_class\": {},  # {class: count}\n",
    "    }\n",
    "\n",
    "    # 去重缓存\n",
    "    seen_hashes_global = {}\n",
    "    seen_hashes_per_class = {}\n",
    "\n",
    "    problems = {\n",
    "        \"unreadable\": [],  # (class, path)\n",
    "        \"too_small\": [],  # (class, path, size)\n",
    "        \"dup_same_class\": [],  # (class, path, dup_of_path)\n",
    "        \"dup_cross_class\": [],  # (class, path, dup_class, dup_of_path)\n",
    "        \"bad_ext\": [],  # (class, path)\n",
    "    }\n",
    "\n",
    "    for cls, path in tqdm(list(_iter_class_images(src_dir)), desc=\"Scanning\"):\n",
    "        stats[\"total_found\"] += 1\n",
    "        # 打开图片 & 基本过滤\n",
    "        try:\n",
    "            img, w, h = _pil_open_rgb(str(path))\n",
    "        except (UnidentifiedImageError, OSError) as e:\n",
    "            stats[\"skipped_unreadable\"] += 1\n",
    "            problems[\"unreadable\"].append((cls, str(path)))\n",
    "            continue\n",
    "\n",
    "        if min(w, h) < min_side:\n",
    "            stats[\"skipped_too_small\"] += 1\n",
    "            problems[\"too_small\"].append((cls, str(path), (w, h)))\n",
    "            continue\n",
    "\n",
    "        # 扩展名检查（允许但会统一保存为 .jpg）\n",
    "        if _safe_ext(path) not in ALLOW_EXTS:\n",
    "            problems[\"bad_ext\"].append((cls, str(path)))\n",
    "\n",
    "        # 去重（可选）\n",
    "        is_dup = False\n",
    "        dup_of = None\n",
    "        if do_dedup:\n",
    "            hval = _ahash(img)  # int\n",
    "            if dedupe_scope == \"class\":\n",
    "                seen_hashes_per_class.setdefault(cls, {})\n",
    "                if hval in seen_hashes_per_class[cls]:\n",
    "                    is_dup = True\n",
    "                    dup_of = seen_hashes_per_class[cls][hval]\n",
    "                    problems[\"dup_same_class\"].append((cls, str(path), dup_of))\n",
    "                else:\n",
    "                    seen_hashes_per_class[cls][hval] = str(path)\n",
    "            else:  # global\n",
    "                if hval in seen_hashes_global:\n",
    "                    prev_cls, prev_path = seen_hashes_global[hval]\n",
    "                    is_dup = True\n",
    "                    dup_of = prev_path\n",
    "                    if prev_cls == cls:\n",
    "                        problems[\"dup_same_class\"].append((cls, str(path), dup_of))\n",
    "                    else:\n",
    "                        problems[\"dup_cross_class\"].append((cls, str(path), prev_cls, dup_of))\n",
    "                else:\n",
    "                    seen_hashes_global[hval] = (cls, str(path))\n",
    "\n",
    "        if is_dup:\n",
    "            # 直接跳过重复项\n",
    "            stats[\"skipped_other\"] += 1\n",
    "            continue\n",
    "\n",
    "        # 保存为统一 jpg 到 dst_dir/class/filename.jpg（保留相对结构）\n",
    "        out_cls_dir = Path(dst_dir) / cls\n",
    "        out_cls_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 文件名去除原扩展，统一 .jpg\n",
    "        stem = path.stem\n",
    "        out_path = out_cls_dir / f\"{stem}.jpg\"\n",
    "\n",
    "        # 若重名则添加计数后缀\n",
    "        suf_idx = 1\n",
    "        while out_path.exists():\n",
    "            out_path = out_cls_dir / f\"{stem}__{suf_idx}.jpg\"\n",
    "            suf_idx += 1\n",
    "\n",
    "        img.save(out_path, format=\"JPEG\", quality=95)\n",
    "        stats[\"copied\"] += 1\n",
    "        stats[\"by_class\"][cls] = stats[\"by_class\"].get(cls, 0) + 1\n",
    "\n",
    "    return stats, problems\n",
    "\n",
    "\n",
    "stats, problems = scan_and_clean()\n",
    "print(\"=== Clean Summary ===\")\n",
    "print(stats)\n",
    "print(\"Unreadable:\", len(problems[\"unreadable\"]),\n",
    "      \"| Too small:\", len(problems[\"too_small\"]),\n",
    "      \"| Dup(same class):\", len(problems[\"dup_same_class\"]),\n",
    "      \"| Dup(cross class):\", len(problems[\"dup_cross_class\"]))\n"
   ],
   "id": "b337d6b50efd5aa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### 3.1 Inspect issues & class distribution after cleaning\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def _preview_list(name, items, k=5):\n",
    "    print(f\"\\n-- {name} (showing up to {k}) --\")\n",
    "    for row in items[:k]:\n",
    "        print(row)\n",
    "\n",
    "\n",
    "_preview_list(\"unreadable\", problems[\"unreadable\"])\n",
    "_preview_list(\"too_small\", problems[\"too_small\"])\n",
    "_preview_list(\"dup_same_class\", problems[\"dup_same_class\"])\n",
    "_preview_list(\"dup_cross_class\", problems[\"dup_cross_class\"])\n",
    "\n",
    "# 清洗后类分布\n",
    "clean_counts = Counter()\n",
    "for cls, p in _iter_class_images(CLEAN_DIR):\n",
    "    clean_counts[cls] += 1\n",
    "\n",
    "df_clean = pd.DataFrame(sorted(clean_counts.items(), key=lambda x: x[0]), columns=[\"class\", \"count\"])\n",
    "fig = px.bar(df_clean, x=\"class\", y=\"count\", title=\"Class Distribution (CLEANED)\", text=\"count\")\n",
    "fig.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "display(fig)\n",
    "\n",
    "print(\"Total after cleaning:\", sum(clean_counts.values()))\n"
   ],
   "id": "2194e22580debc65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### 3.2 Enhancement — imbalance handling, RandAugment & MixUp\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "# 计算类别采样权重（用于 WeightedRandomSampler）\n",
    "def compute_sampler_weights(root_dir: str = CLEAN_DIR):\n",
    "    class_to_idx = {}\n",
    "    # 使用与 ImageFolder 相同的类别顺序\n",
    "    for i, cls in enumerate(sorted([d.name for d in Path(root_dir).iterdir() if d.is_dir()])):\n",
    "        class_to_idx[cls] = i\n",
    "\n",
    "    per_class_counts = np.zeros(len(class_to_idx), dtype=np.int64)\n",
    "    samples = []  # (path, class_idx)\n",
    "\n",
    "    for cls, p in _iter_class_images(root_dir):\n",
    "        ci = class_to_idx[cls]\n",
    "        per_class_counts[ci] += 1\n",
    "        samples.append((str(p), ci))\n",
    "\n",
    "    # 避免除零\n",
    "    per_class_counts = np.maximum(per_class_counts, 1)\n",
    "    class_weights = 1.0 / per_class_counts\n",
    "    weights = [class_weights[ci] for _, ci in samples]\n",
    "\n",
    "    # 不平衡度\n",
    "    imb_ratio = float(per_class_counts.max() / per_class_counts.min())\n",
    "    return weights, class_to_idx, per_class_counts, imb_ratio\n",
    "\n",
    "\n",
    "weights, class_to_idx_clean, per_class_counts, imb_ratio = compute_sampler_weights(CLEAN_DIR)\n",
    "print(\"Class order:\", class_to_idx_clean)\n",
    "print(\"Counts:\", per_class_counts, \"| imbalance ratio (max/min):\", round(imb_ratio, 3))\n",
    "\n",
    "USE_SAMPLER = imb_ratio >= 1.5  # 阈值\n",
    "print(\"USE_SAMPLER =\", USE_SAMPLER)\n",
    "\n",
    "# 自动拼接 RandAugment 到 train_tf\n",
    "try:\n",
    "    if hasattr(T, \"RandAugment\"):\n",
    "        train_tf = T.Compose([\n",
    "            T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            T.RandAugment(num_ops=2, magnitude=7),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.RandomRotation(10),\n",
    "            T.ColorJitter(0.1, 0.1, 0.05),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "        ])\n",
    "        print(\"RandAugment enabled.\")\n",
    "    else:\n",
    "        print(\"RandAugment not available in this torchvision version; skipped.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to enable RandAugment:\", e)\n",
    "\n",
    "\n",
    "# MixUp collate_fn（训练 loader 使用）\n",
    "def mixup_collate_fn(batch, alpha: float = 0.2, num_classes: int = None):\n",
    "    \"\"\"\n",
    "    batch: list of (img_tensor[C,H,W], label_idx)\n",
    "    返回： (mixed_x, mixed_y_onehot) with lambda\n",
    "    \"\"\"\n",
    "    xs, ys = zip(*batch)\n",
    "    x = torch.stack(xs, dim=0)\n",
    "    y = torch.tensor(ys, dtype=torch.long)\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = len(class_to_idx_clean)\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0.0 else 1.0\n",
    "    index = torch.randperm(x.size(0))\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_onehot = torch.zeros((x.size(0), num_classes), dtype=torch.float32)\n",
    "    y_onehot.scatter_(1, y.view(-1, 1), 1.0)\n",
    "    y_shuffled = y[index]\n",
    "    y_shuf_onehot = torch.zeros_like(y_onehot)\n",
    "    y_shuf_onehot.scatter_(1, y_shuffled.view(-1, 1), 1.0)\n",
    "\n",
    "    mixed_y = lam * y_onehot + (1 - lam) * y_shuf_onehot\n",
    "    return mixed_x, mixed_y\n"
   ],
   "id": "59289c8667f285fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### 3.3 Rebuild loaders from CLEAN_DIR\n",
    "def get_loaders_clean(\n",
    "        data_dir: str = CLEAN_DIR,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        val_split: float = VAL_SPLIT,\n",
    "        seed: int = SEED,\n",
    "        num_workers: int = NUM_WORKERS,\n",
    "        pin_memory: bool = PIN,\n",
    "        use_sampler: bool = USE_SAMPLER,\n",
    "        use_mixup: bool = False\n",
    "):\n",
    "    full = torchvision.datasets.ImageFolder(root=data_dir, transform=train_tf)\n",
    "    n = len(full)\n",
    "    n_val = int(n * val_split)\n",
    "    n_train = n - n_val\n",
    "\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    train_set, val_set = random_split(full, [n_train, n_val], generator=g)\n",
    "    # val 使用干净的 tf\n",
    "    val_set.dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=val_tf)\n",
    "\n",
    "    class_to_idx = full.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "    # 构建采样器（仅训练集）\n",
    "    sampler = None\n",
    "    if use_sampler:\n",
    "        # 需要把 weights 对应到 train_set 的索引\n",
    "        # 重新基于 train_set 的样本路径计算权重\n",
    "        train_paths = []\n",
    "        train_labels = []\n",
    "        for i in range(len(train_set)):\n",
    "            p, y = full.samples[train_set.indices[i]]  # (path, class_idx)\n",
    "            train_paths.append(p)\n",
    "            train_labels.append(y)\n",
    "\n",
    "        # 统计训练集内的 per-class counts\n",
    "        tr_counts = np.zeros(len(class_to_idx), dtype=np.int64)\n",
    "        for y in train_labels:\n",
    "            tr_counts[y] += 1\n",
    "        tr_counts = np.maximum(tr_counts, 1)\n",
    "        tr_class_w = 1.0 / tr_counts\n",
    "        tr_weights = torch.DoubleTensor([tr_class_w[y] for y in train_labels])\n",
    "        sampler = WeightedRandomSampler(tr_weights, num_samples=len(tr_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(sampler is None),\n",
    "        sampler=sampler,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=False,\n",
    "        collate_fn=(lambda b: mixup_collate_fn(b, alpha=0.2, num_classes=len(class_to_idx))) if use_mixup else None\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=batch_size * 2, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n",
    "    )\n",
    "    return train_loader, val_loader, idx_to_class\n",
    "\n",
    "\n",
    "# 使用 CLEAN 集合重建 DataLoader\n",
    "train_loader, val_loader, idx_to_class = get_loaders_clean(\n",
    "    use_sampler=USE_SAMPLER,\n",
    "    use_mixup=False,  # 如需 MixUp，将其改为 True；注意你的损失函数需支持 soft labels（如 BCE 或自定义 KL/CE）\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"CLEAN train batch:\", xb.shape, \"| y type:\", type(yb))\n"
   ],
   "id": "a6b2d8581ffb3673"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Model and comparison model",
   "id": "4ca56961470789d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_resnet50_classifier(num_classes=23, input_shape=(224, 224, 3), base_trainable=False):\n",
    "    input = layers.Input(shape=input_shape)\n",
    "    x = preprocess_input(input)                    # preprocess\n",
    "    base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
    "    base.trainable = base_trainable\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(input, out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")])\n",
    "    return model\n"
   ],
   "id": "a07dcecc47775f64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7645ffddd66816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e25e0d26513f0013"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Model training",
   "id": "62bd416a8a3e43dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6366fa046582aea7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "608a68ca238ca833"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af5571ab808e851"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6. Model performance comparison & CV",
   "id": "d499f932368ac371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "770d5e3184900224"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "686e7bad86f3b4ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
