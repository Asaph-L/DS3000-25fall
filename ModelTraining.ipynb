{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6444ba16d9c9dd45",
   "metadata": {},
   "source": [
    "#### 1. Data import and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63716474f21b8a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:33:38.928345Z",
     "start_time": "2025-12-06T05:33:36.904983Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fb87c4f652cf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:33:55.812960Z",
     "start_time": "2025-12-06T05:33:38.934780Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- config ---\n",
    "ROOT = Path().resolve()\n",
    "DATA_DIR = os.path.join(ROOT, \"data\", \"archive\", \"Dataset\")\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "NUM_WORKERS = 4\n",
    "PIN = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if PIN else \"cpu\")\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# --- transforms ---\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(0.5),\n",
    "    T.RandomRotation(10),\n",
    "    T.ColorJitter(0.1, 0.1, 0.05),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "\n",
    "def get_loaders(\n",
    "        data_dir: str = DATA_DIR,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        val_split: float = VAL_SPLIT,\n",
    "        seed: int = SEED,\n",
    "        num_workers: int = NUM_WORKERS,\n",
    "        pin_memory: bool = PIN,\n",
    "):\n",
    "    full = torchvision.datasets.ImageFolder(root=data_dir, transform=train_tf)\n",
    "    n = len(full)\n",
    "    n_val = int(n * val_split)\n",
    "    n_train = n - n_val\n",
    "\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    train_set, val_set = random_split(full, [n_train, n_val], generator=g)\n",
    "\n",
    "    # clean tf for val\n",
    "    val_set.dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=val_tf)\n",
    "\n",
    "    class_to_idx = full.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=batch_size * 2, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n",
    "    )\n",
    "    return train_loader, val_loader, idx_to_class\n",
    "\n",
    "train_loader, val_loader, idx_to_class = get_loaders()\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b48504300c440",
   "metadata": {},
   "source": [
    "#### 2.Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e3ebc04cd0a8b",
   "metadata": {},
   "source": [
    "show image amount, show class amount,and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b18cc8b4d14bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:33:57.646654Z",
     "start_time": "2025-12-06T05:33:57.636146Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Total images: {len(train_loader.dataset) + len(val_loader.dataset)}  |  \"\n",
    "      f\"Train: {len(train_loader.dataset)}  Val: {len(val_loader.dataset)}\")\n",
    "print(\"Num classes:\", len(idx_to_class))\n",
    "print(\"Classes:\", list(idx_to_class.values()))\n",
    "print(\"Batch:\", xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6f6c81f48c266",
   "metadata": {},
   "source": [
    "Display the first 10 images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb80c9eb6c64f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:33:57.747899Z",
     "start_time": "2025-12-06T05:33:57.676365Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = train_loader.dataset\n",
    "for i in range(9):\n",
    "    img, label = dataset[i]\n",
    "    img = img.detach().cpu()\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    if img.shape[0] == 3:\n",
    "        img = img * std + mean\n",
    "\n",
    "    img = img.permute(1, 2, 0).clamp(0, 1)  # HWC, [0,1]\n",
    "    img = (img * 255).byte().numpy()  # uint8 array\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    display(img)\n",
    "\n",
    "    real_class_name = idx_to_class[label]\n",
    "    print(real_class_name, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc706c822944bf",
   "metadata": {},
   "source": [
    "Count images per class to check class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad06588b6cd6e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:33:57.763721Z",
     "start_time": "2025-12-06T05:33:57.754426Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# for img, label in dataset:\n",
    "#     labels.append(idx_to_class[label])\n",
    "\n",
    "labels = [idx_to_class[label] for label in train_loader.dataset.dataset.targets]\n",
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddedecca1ab9d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:33:58.723822Z",
     "start_time": "2025-12-06T05:33:57.767896Z"
    }
   },
   "outputs": [],
   "source": [
    "count = Counter(labels)\n",
    "\n",
    "df = pd.DataFrame(sorted(count.items(), key=lambda x: x[0]), columns=[\"class\", \"count\"])\n",
    "\n",
    "fig = px.bar(df, x=\"class\", y=\"count\", title=\"Class Distribution\", text=\"count\")\n",
    "fig.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ed806a6c5aff0",
   "metadata": {},
   "source": [
    "#### 3. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb5c5df92e81de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:35.060138Z",
     "start_time": "2025-12-06T05:33:58.750727Z"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Data cleaning (Optimized with Parallel Processing)\n",
    "import shutil\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "CLEAN_DIR = os.path.join(ROOT, \"data\", \"clean\")\n",
    "MIN_SIDE = 64\n",
    "ALLOW_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "DO_DEDUP = True\n",
    "DEDUPE_SCOPE = \"global\"\n",
    "NUM_WORKERS = 16  # Number of parallel threads\n",
    "\n",
    "\n",
    "def _safe_ext(p: Path) -> str:\n",
    "    return p.suffix.lower()\n",
    "\n",
    "\n",
    "def _is_image_file(p: Path) -> bool:\n",
    "    return _safe_ext(p) in ALLOW_EXTS\n",
    "\n",
    "\n",
    "def _pil_open_rgb(path: str):\n",
    "    with Image.open(path) as im:\n",
    "        im.load()\n",
    "        im = im.convert(\"RGB\")\n",
    "        w, h = im.size\n",
    "    return im, w, h\n",
    "\n",
    "\n",
    "def _ahash(img: Image.Image, hash_size: int = 8) -> int:\n",
    "    g = img.convert(\"L\").resize((hash_size, hash_size), Image.Resampling.BILINEAR)\n",
    "    arr = np.asarray(g, dtype=np.float32)\n",
    "    mean = arr.mean()\n",
    "    bits = (arr >= mean).astype(np.uint8).ravel()\n",
    "    h = 0\n",
    "    for b in bits:\n",
    "        h = (h << 1) | int(b)\n",
    "    return h\n",
    "\n",
    "\n",
    "def _iter_class_images(root_dir: str):\n",
    "    root = Path(root_dir)\n",
    "    for cls_dir in sorted([d for d in root.iterdir() if d.is_dir()]):\n",
    "        cls = cls_dir.name\n",
    "        for p in cls_dir.rglob(\"*\"):\n",
    "            if p.is_file() and _is_image_file(p):\n",
    "                yield cls, p\n",
    "\n",
    "\n",
    "def _process_single_image(args):\n",
    "    \"\"\"Process a single image - designed for parallel execution\"\"\"\n",
    "    cls, path, min_side, dst_dir = args\n",
    "    \n",
    "    result = {\n",
    "        'cls': cls,\n",
    "        'path': str(path),\n",
    "        'status': 'ok',\n",
    "        'hash': None,\n",
    "        'size': None,\n",
    "        'out_path': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        img, w, h = _pil_open_rgb(str(path))\n",
    "        result['size'] = (w, h)\n",
    "        \n",
    "        if min(w, h) < min_side:\n",
    "            result['status'] = 'too_small'\n",
    "            return result\n",
    "        \n",
    "        # Compute hash for deduplication\n",
    "        result['hash'] = _ahash(img)\n",
    "        \n",
    "        # Prepare output path\n",
    "        out_cls_dir = Path(dst_dir) / cls\n",
    "        out_cls_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        stem = path.stem\n",
    "        out_path = out_cls_dir / f\"{stem}.jpg\"\n",
    "        \n",
    "        suf_idx = 1\n",
    "        while out_path.exists():\n",
    "            out_path = out_cls_dir / f\"{stem}__{suf_idx}.jpg\"\n",
    "            suf_idx += 1\n",
    "        \n",
    "        # Save image\n",
    "        img.save(out_path, format=\"JPEG\", quality=95)\n",
    "        result['out_path'] = str(out_path)\n",
    "        \n",
    "    except (UnidentifiedImageError, OSError, Exception) as e:\n",
    "        result['status'] = 'unreadable'\n",
    "        result['error'] = str(e)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def scan_and_clean(\n",
    "        src_dir: str = DATA_DIR,\n",
    "        dst_dir: str = CLEAN_DIR,\n",
    "        min_side: int = MIN_SIDE,\n",
    "        do_dedup: bool = DO_DEDUP,\n",
    "        dedupe_scope: str = DEDUPE_SCOPE,\n",
    "        num_workers: int = NUM_WORKERS,\n",
    "):\n",
    "    print(f\"Using {num_workers} parallel threads for faster cleaning...\")\n",
    "    \n",
    "    if os.path.exists(dst_dir):\n",
    "        shutil.rmtree(dst_dir)\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    stats = {\n",
    "        \"total_found\": 0,\n",
    "        \"copied\": 0,\n",
    "        \"skipped_unreadable\": 0,\n",
    "        \"skipped_too_small\": 0,\n",
    "        \"skipped_other\": 0,\n",
    "        \"by_class\": {},\n",
    "    }\n",
    "\n",
    "    seen_hashes_global = {}\n",
    "    seen_hashes_per_class = {}\n",
    "\n",
    "    problems = {\n",
    "        \"unreadable\": [],\n",
    "        \"too_small\": [],\n",
    "        \"dup_same_class\": [],\n",
    "        \"dup_cross_class\": [],\n",
    "        \"bad_ext\": [],\n",
    "    }\n",
    "\n",
    "    # Collect all images first\n",
    "    print(\"Collecting all images...\")\n",
    "    all_images = list(_iter_class_images(src_dir))\n",
    "    stats[\"total_found\"] = len(all_images)\n",
    "    print(f\"Found {stats['total_found']} images to process\")\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    process_args = [(cls, path, min_side, dst_dir) for cls, path in all_images]\n",
    "    \n",
    "    # Process images in parallel with progress bar using ThreadPoolExecutor\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        futures = [executor.submit(_process_single_image, args) for args in process_args]\n",
    "        \n",
    "        # Process results as they complete with progress bar\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing images\"):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError processing image: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Process results and handle deduplication\n",
    "    for result in results:\n",
    "        cls = result['cls']\n",
    "        path = result['path']\n",
    "        status = result['status']\n",
    "        \n",
    "        if status == 'unreadable':\n",
    "            stats[\"skipped_unreadable\"] += 1\n",
    "            problems[\"unreadable\"].append((cls, path))\n",
    "            continue\n",
    "        \n",
    "        if status == 'too_small':\n",
    "            stats[\"skipped_too_small\"] += 1\n",
    "            problems[\"too_small\"].append((cls, path, result['size']))\n",
    "            continue\n",
    "        \n",
    "        # Check for duplicates\n",
    "        is_dup = False\n",
    "        if do_dedup and result['hash'] is not None:\n",
    "            hval = result['hash']\n",
    "            if dedupe_scope == \"class\":\n",
    "                seen_hashes_per_class.setdefault(cls, {})\n",
    "                if hval in seen_hashes_per_class[cls]:\n",
    "                    is_dup = True\n",
    "                    dup_of = seen_hashes_per_class[cls][hval]\n",
    "                    problems[\"dup_same_class\"].append((cls, path, dup_of))\n",
    "                    # Remove the duplicate file\n",
    "                    if result['out_path'] and os.path.exists(result['out_path']):\n",
    "                        os.remove(result['out_path'])\n",
    "                else:\n",
    "                    seen_hashes_per_class[cls][hval] = path\n",
    "            else:  # global\n",
    "                if hval in seen_hashes_global:\n",
    "                    prev_cls, prev_path = seen_hashes_global[hval]\n",
    "                    is_dup = True\n",
    "                    if prev_cls == cls:\n",
    "                        problems[\"dup_same_class\"].append((cls, path, prev_path))\n",
    "                    else:\n",
    "                        problems[\"dup_cross_class\"].append((cls, path, prev_cls, prev_path))\n",
    "                    # Remove the duplicate file\n",
    "                    if result['out_path'] and os.path.exists(result['out_path']):\n",
    "                        os.remove(result['out_path'])\n",
    "                else:\n",
    "                    seen_hashes_global[hval] = (cls, path)\n",
    "        \n",
    "        if is_dup:\n",
    "            stats[\"skipped_other\"] += 1\n",
    "        else:\n",
    "            stats[\"copied\"] += 1\n",
    "            stats[\"by_class\"][cls] = stats[\"by_class\"].get(cls, 0) + 1\n",
    "\n",
    "    return stats, problems\n",
    "\n",
    "\n",
    "stats, problems = scan_and_clean()\n",
    "print(\"\\n=== Clean Summary ===\")\n",
    "print(stats)\n",
    "print(\"Unreadable:\", len(problems[\"unreadable\"]),\n",
    "      \"| Too small:\", len(problems[\"too_small\"]),\n",
    "      \"| Dup(same class):\", len(problems[\"dup_same_class\"]),\n",
    "      \"| Dup(cross class):\", len(problems[\"dup_cross_class\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0696c20b4d56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:37.535876Z",
     "start_time": "2025-12-06T05:36:35.156641Z"
    }
   },
   "outputs": [],
   "source": [
    "### 3.1 Inspect issues & class distribution after cleaning\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def _preview_list(name, items, k=5):\n",
    "    print(f\"\\n-- {name} (showing up to {k}) --\")\n",
    "    for row in items[:k]:\n",
    "        print(row)\n",
    "\n",
    "\n",
    "_preview_list(\"unreadable\", problems[\"unreadable\"])\n",
    "_preview_list(\"too_small\", problems[\"too_small\"])\n",
    "_preview_list(\"dup_same_class\", problems[\"dup_same_class\"])\n",
    "_preview_list(\"dup_cross_class\", problems[\"dup_cross_class\"])\n",
    "\n",
    "clean_counts = Counter()\n",
    "for cls, p in _iter_class_images(CLEAN_DIR):\n",
    "    clean_counts[cls] += 1\n",
    "\n",
    "df_clean = pd.DataFrame(sorted(clean_counts.items(), key=lambda x: x[0]), columns=[\"class\", \"count\"])\n",
    "fig = px.bar(df_clean, x=\"class\", y=\"count\", title=\"Class Distribution (CLEANED)\", text=\"count\")\n",
    "fig.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "display(fig)\n",
    "\n",
    "print(\"Total after cleaning:\", sum(clean_counts.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e525de797e40d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:38.695800Z",
     "start_time": "2025-12-06T05:36:37.764402Z"
    }
   },
   "outputs": [],
   "source": [
    "### 3.2 Enhancement — imbalance handling, RandAugment & MixUp\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "def compute_sampler_weights(root_dir: str = CLEAN_DIR):\n",
    "    class_to_idx = {}\n",
    "    for i, cls in enumerate(sorted([d.name for d in Path(root_dir).iterdir() if d.is_dir()])):\n",
    "        class_to_idx[cls] = i\n",
    "\n",
    "    per_class_counts = np.zeros(len(class_to_idx), dtype=np.int64)\n",
    "    samples = []  # (path, class_idx)\n",
    "\n",
    "    for cls, p in _iter_class_images(root_dir):\n",
    "        ci = class_to_idx[cls]\n",
    "        per_class_counts[ci] += 1\n",
    "        samples.append((str(p), ci))\n",
    "\n",
    "    per_class_counts = np.maximum(per_class_counts, 1)\n",
    "    class_weights = 1.0 / per_class_counts\n",
    "    weights = [class_weights[ci] for _, ci in samples]\n",
    "\n",
    "    imb_ratio = float(per_class_counts.max() / per_class_counts.min())\n",
    "    return weights, class_to_idx, per_class_counts, imb_ratio\n",
    "\n",
    "\n",
    "weights, class_to_idx_clean, per_class_counts, imb_ratio = compute_sampler_weights(CLEAN_DIR)\n",
    "print(\"Class order:\", class_to_idx_clean)\n",
    "print(\"Counts:\", per_class_counts, \"| imbalance ratio (max/min):\", round(imb_ratio, 3))\n",
    "\n",
    "USE_SAMPLER = imb_ratio >= 1.5  # 阈值\n",
    "print(\"USE_SAMPLER =\", USE_SAMPLER)\n",
    "\n",
    "try:\n",
    "    if hasattr(T, \"RandAugment\"):\n",
    "        train_tf = T.Compose([\n",
    "            T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            T.RandAugment(num_ops=2, magnitude=7),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.RandomRotation(10),\n",
    "            T.ColorJitter(0.1, 0.1, 0.05),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "        ])\n",
    "        print(\"RandAugment enabled.\")\n",
    "    else:\n",
    "        print(\"RandAugment not available in this torchvision version; skipped.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to enable RandAugment:\", e)\n",
    "\n",
    "\n",
    "def mixup_collate_fn(batch, alpha: float = 0.2, num_classes: int = None):\n",
    "    \"\"\"\n",
    "    batch: list of (img_tensor[C,H,W], label_idx)\n",
    "    \"\"\"\n",
    "    xs, ys = zip(*batch)\n",
    "    x = torch.stack(xs, dim=0)\n",
    "    y = torch.tensor(ys, dtype=torch.long)\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = len(class_to_idx_clean)\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0.0 else 1.0\n",
    "    index = torch.randperm(x.size(0))\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_onehot = torch.zeros((x.size(0), num_classes), dtype=torch.float32)\n",
    "    y_onehot.scatter_(1, y.view(-1, 1), 1.0)\n",
    "    y_shuffled = y[index]\n",
    "    y_shuf_onehot = torch.zeros_like(y_onehot)\n",
    "    y_shuf_onehot.scatter_(1, y_shuffled.view(-1, 1), 1.0)\n",
    "\n",
    "    mixed_y = lam * y_onehot + (1 - lam) * y_shuf_onehot\n",
    "    return mixed_x, mixed_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a15f12b8d87f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:56.468768Z",
     "start_time": "2025-12-06T05:36:38.726033Z"
    }
   },
   "outputs": [],
   "source": [
    "### 3.3 Rebuild loaders from CLEAN_DIR\n",
    "def get_loaders_clean(\n",
    "        data_dir: str = CLEAN_DIR,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        val_split: float = VAL_SPLIT,\n",
    "        seed: int = SEED,\n",
    "        num_workers: int = NUM_WORKERS,\n",
    "        pin_memory: bool = PIN,\n",
    "        use_sampler: bool = USE_SAMPLER,\n",
    "        use_mixup: bool = False\n",
    "):\n",
    "    full = torchvision.datasets.ImageFolder(root=data_dir, transform=train_tf)\n",
    "    n = len(full)\n",
    "    n_val = int(n * val_split)\n",
    "    n_train = n - n_val\n",
    "\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    train_set, val_set = random_split(full, [n_train, n_val], generator=g)\n",
    "    val_set.dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=val_tf)\n",
    "\n",
    "    class_to_idx = full.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "    sampler = None\n",
    "    if use_sampler:\n",
    "        train_paths = []\n",
    "        train_labels = []\n",
    "        for i in range(len(train_set)):\n",
    "            p, y = full.samples[train_set.indices[i]]  # (path, class_idx)\n",
    "            train_paths.append(p)\n",
    "            train_labels.append(y)\n",
    "\n",
    "        tr_counts = np.zeros(len(class_to_idx), dtype=np.int64)\n",
    "        for y in train_labels:\n",
    "            tr_counts[y] += 1\n",
    "        tr_counts = np.maximum(tr_counts, 1)\n",
    "        tr_class_w = 1.0 / tr_counts\n",
    "        tr_weights = torch.DoubleTensor([tr_class_w[y] for y in train_labels])\n",
    "        sampler = WeightedRandomSampler(tr_weights, num_samples=len(tr_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(sampler is None),\n",
    "        sampler=sampler,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=False,\n",
    "        collate_fn=(lambda b: mixup_collate_fn(b, alpha=0.2, num_classes=len(class_to_idx))) if use_mixup else None\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=batch_size * 2, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n",
    "    )\n",
    "    return train_loader, val_loader, idx_to_class\n",
    "\n",
    "\n",
    "train_loader, val_loader, idx_to_class = get_loaders_clean(\n",
    "    use_sampler=USE_SAMPLER,\n",
    "    use_mixup=False,\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"CLEAN train batch:\", xb.shape, \"| y type:\", type(yb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdd89ad6623fed",
   "metadata": {},
   "source": [
    "#### 4. Model and comparison model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2caff2ee5587194",
   "metadata": {},
   "source": [
    "ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e12ff0e332e9b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:56.506254Z",
     "start_time": "2025-12-06T05:36:56.490339Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_resnet50_classifier(num_classes=23, input_shape=(224, 224, 3), base_trainable=False):\n",
    "#     input = layers.Input(shape=input_shape)\n",
    "#     x = preprocess_input(input)                    # preprocess\n",
    "#     base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
    "#     base.trainable = base_trainable\n",
    "#     x = layers.GlobalAveragePooling2D()(base.output)\n",
    "#     x = layers.Dropout(0.2)(x)\n",
    "#     out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "#     model = Model(input, out)\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "#                   loss=\"sparse_categorical_crossentropy\",\n",
    "#                   metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")])\n",
    "#     return model\n",
    "import torch.nn as nn\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "def build_resnet50_classifier(num_classes=23):\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e51f46ffb2f3c",
   "metadata": {},
   "source": [
    "EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d59980e9d2ec773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:56.525637Z",
     "start_time": "2025-12-06T05:36:56.509969Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_efficientnet_classifier(num_classes=23):\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79cd0221a23fa0d",
   "metadata": {},
   "source": [
    "Our own 20-layer CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a7a7989dd3105f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:56.547322Z",
     "start_time": "2025-12-06T05:36:56.531056Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Define the 20-Layer CNN Architecture ---\n",
    "# Architecture Design:\n",
    "# Block 1: 2 Conv + MaxPool\n",
    "# Block 2: 2 Conv + MaxPool\n",
    "# Block 3: 4 Conv + MaxPool\n",
    "# Block 4: 4 Conv + MaxPool\n",
    "# Block 5: 4 Conv + MaxPool\n",
    "# Classifier: 4 FC layers\n",
    "# Total learnable layers: 2 + 2 + 4 + 4 + 4 + 4 = 20 layers\n",
    "\n",
    "class CNN20Model(nn.Module):\n",
    "    def __init__(self, num_classes=23):\n",
    "        super(CNN20Model, self).__init__()\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1 (Input: 3x224x224 -> Output: 64x112x112)\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 2 (Output: 128x56x56)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 3 (Output: 256x28x28)\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 4 (Output: 512x14x14)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 5 (Output: 512x7x7)\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Classifier (Fully Connected Layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(1000, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a86127f1b169f",
   "metadata": {},
   "source": [
    "#### 5. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df2cda761735a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:56.564730Z",
     "start_time": "2025-12-06T05:36:56.552513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 5  # Early stopping patience\n",
    "\n",
    "# Move to device\n",
    "print(f\"Training on: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541401a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:21:26.264921Z",
     "start_time": "2025-12-06T06:21:19.063462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clear CUDA cache and reset data loaders to avoid memory conflicts\n",
    "import gc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"✓ CUDA cache cleared\")\n",
    "\n",
    "# Recreate data loaders with fresh instances to avoid pin_memory conflicts\n",
    "gc.collect()\n",
    "train_loader, val_loader, idx_to_class = get_loaders()\n",
    "print(f\"✓ Data loaders recreated successfully\")\n",
    "print(f\"  Train samples: {len(train_loader.dataset)}\")\n",
    "print(f\"  Val samples: {len(val_loader.dataset)}\")\n",
    "print(f\"  Classes: {len(idx_to_class)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9638827aa84f3f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:56.911557Z",
     "start_time": "2025-12-06T05:36:56.900452Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "493e733707f9c9c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T05:36:56.927220Z",
     "start_time": "2025-12-06T05:36:56.915621Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=EPOCHS, lr=LEARNING_RATE,\n",
    "                weight_decay=WEIGHT_DECAY, patience=PATIENCE, model_name=\"model\"):\n",
    "    \"\"\"Complete training loop with early stopping and checkpointing\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    print(f\"\\nStarting training for {model_name}...\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:6.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:6.2f}%\", end=\"\", flush=True)\n",
    "\n",
    "        # Early stopping & checkpoint\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), f'best_{model_name}.pth')\n",
    "            print(f\" ✓ [Best: {val_acc:.2f}%]\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(flush=True)\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            print(f\"Best validation accuracy: {best_val_acc:.2f}% (epoch {best_epoch})\")\n",
    "            break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(torch.load(f'best_{model_name}.pth'))\n",
    "    print(f\"\\nTraining complete! Best model saved as 'best_{model_name}.pth'\")\n",
    "    print(\"-\" * 70)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cf20c17db8bb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.123095Z",
     "start_time": "2025-12-06T05:36:56.930711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train ResNet50\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING RESNET50\")\n",
    "print(\"=\" * 70)\n",
    "resnet_model = build_resnet50_classifier(num_classes=len(idx_to_class))\n",
    "resnet_model, resnet_history = train_model(\n",
    "    resnet_model, train_loader, val_loader,\n",
    "    model_name=\"resnet50\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0f4e0428ccb21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.204776600Z",
     "start_time": "2025-11-13T11:51:00.778690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train EfficientNetB0\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING EFFICIENTNETB0\")\n",
    "print(\"=\" * 70)\n",
    "efficientnet_model = build_efficientnet_classifier(num_classes=len(idx_to_class))\n",
    "efficientnet_model, efficientnet_history = train_model(\n",
    "    efficientnet_model, train_loader, val_loader,\n",
    "    model_name=\"efficientnet_b0\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be0fb60fdf7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Custom Model\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING CUSTOM 20-LAYER CNN MODEL\")\n",
    "print(\"=\" * 70)\n",
    "NUM_CLASSES = len(idx_to_class)\n",
    "print(f\"Initializing 20-layer CNN for {NUM_CLASSES} classes on device: {device}\")\n",
    "model_20 = CNN20Model(num_classes=NUM_CLASSES).to(device)\n",
    "model_20, model_20_history = train_model(\n",
    "    model_20, train_loader, val_loader,\n",
    "    model_name=\"cnn_20\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb219907e122b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.204776600Z",
     "start_time": "2025-11-13T12:05:44.002564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save models with complete metadata for future reuse\n",
    "def save_model_with_metadata(model, history, model_name, num_classes, class_mapping):\n",
    "    \"\"\"Save model weights + training history + class mapping\"\"\"\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'history': history,\n",
    "        'num_classes': num_classes,\n",
    "        'class_to_idx': class_mapping,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "    torch.save(checkpoint, f'{model_name}_complete.pth')\n",
    "    print(f\"Saved {model_name} with metadata to '{model_name}_complete.pth'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save all models\n",
    "# save_model_with_metadata(resnet_model, resnet_history, 'resnet50',\n",
    "#                          len(idx_to_class), train_loader.dataset.dataset.class_to_idx)\n",
    "# save_model_with_metadata(efficientnet_model, efficientnet_history, 'efficientnet_b0',\n",
    "#                          len(idx_to_class), train_loader.dataset.dataset.class_to_idx)\n",
    "save_model_with_metadata(model_20, model_20_history, 'cnn_20',\n",
    "                         len(idx_to_class), train_loader.dataset.dataset.class_to_idx)\n",
    "\n",
    "print(\"\\nTraining complete for all models\")\n",
    "print(\"Models saved with complete metadata\")\n",
    "print(\"See Section 6 for detailed performance comparison and analysis\")\n",
    "print(\"Use ModelInference.ipynb to reload models without retraining\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc92ef1ba603aa6",
   "metadata": {},
   "source": [
    "#### 6. Model performance comparison & CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c156cc0891acf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.204776600Z",
     "start_time": "2025-11-13T12:05:44.113609Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6.1 Compare training histories from all three models\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def plot_training_histories_comparison(history1, history2, history3, model_name1, model_name2, model_name3):\n",
    "    \"\"\"Compare training histories of three models side by side\"\"\"\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = gridspec.GridSpec(2, 3, figure=fig)\n",
    "\n",
    "    epochs1 = range(1, len(history1['train_loss']) + 1)\n",
    "    epochs2 = range(1, len(history2['train_loss']) + 1)\n",
    "    epochs3 = range(1, len(history3['train_loss']) + 1)\n",
    "\n",
    "    # Model 1 - Loss\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(epochs1, history1['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    ax1.plot(epochs1, history1['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    ax1.set_title(f'{model_name1} - Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Model 2 - Loss\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(epochs2, history2['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    ax2.plot(epochs2, history2['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    ax2.set_title(f'{model_name2} - Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Model 3 - Loss\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(epochs3, history3['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    ax3.plot(epochs3, history3['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    ax3.set_title(f'{model_name3} - Loss', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Loss', fontsize=12)\n",
    "    ax3.set_xlabel('Epoch', fontsize=12)\n",
    "    ax3.legend(fontsize=11)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # Model 1 - Accuracy\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax4.plot(epochs1, history1['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    ax4.plot(epochs1, history1['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    ax4.set_title(f'{model_name1} - Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax4.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax4.set_xlabel('Epoch', fontsize=12)\n",
    "    ax4.legend(fontsize=11)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "    # Model 2 - Accuracy\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax5.plot(epochs2, history2['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    ax5.plot(epochs2, history2['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    ax5.set_title(f'{model_name2} - Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax5.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax5.set_xlabel('Epoch', fontsize=12)\n",
    "    ax5.legend(fontsize=11)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "    # Model 3 - Accuracy\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.plot(epochs3, history3['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    ax6.plot(epochs3, history3['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    ax6.set_title(f'{model_name3} - Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax6.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax6.set_xlabel('Epoch', fontsize=12)\n",
    "    ax6.legend(fontsize=11)\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Plot comparison of all three models\n",
    "plot_training_histories_comparison(resnet_history, efficientnet_history, model_20_history, \n",
    "                                'ResNet50', 'EfficientNetB0', 'Custom CNN-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17b439f917b77b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.204776600Z",
     "start_time": "2025-11-13T12:05:44.408737Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6.2 Detailed evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, top_k_accuracy_score\n",
    "\n",
    "def evaluate_model_pytorch(model, loader, device, k=3):\n",
    "    \"\"\"Evaluate PyTorch model and return metrics\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    # Calculate top-k accuracy\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "    top_k_acc = top_k_accuracy_score(all_labels, all_probs, k=k) * 100\n",
    "\n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'top_k_accuracy': top_k_acc,\n",
    "        'predictions': np.array(all_preds),\n",
    "        'probabilities': all_probs,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "\n",
    "print(\"Evaluating ResNet50...\")\n",
    "resnet_results = evaluate_model_pytorch(resnet_model, val_loader, device, k=3)\n",
    "\n",
    "print(\"Evaluating EfficientNetB0...\")\n",
    "efficientnet_results = evaluate_model_pytorch(efficientnet_model, val_loader, device, k=3)\n",
    "\n",
    "print(\"Evaluating Custom CNN-20...\")\n",
    "model_20_results = evaluate_model_pytorch(model_20, val_loader, device, k=3)\n",
    "\n",
    "# Create comparison table\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['ResNet50', 'EfficientNetB0', 'Custom CNN-20'],\n",
    "    'Validation Loss': [resnet_results['loss'], efficientnet_results['loss'], model_20_results['loss']],\n",
    "    'Validation Accuracy (%)': [resnet_results['accuracy'], efficientnet_results['accuracy'], model_20_results['accuracy']],\n",
    "    'Top-3 Accuracy (%)': [resnet_results['top_k_accuracy'], efficientnet_results['top_k_accuracy'], model_20_results['top_k_accuracy']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "display(results_df.style.format({\n",
    "    'Validation Loss': '{:.4f}',\n",
    "    'Validation Accuracy (%)': '{:.2f}',\n",
    "\n",
    "    'Top-3 Accuracy (%)': '{:.2f}'\n",
    "}).hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442d6b47173fd11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.204776600Z",
     "start_time": "2025-11-13T12:06:04.970009Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6.3 Classification reports and confusion matrices\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Get class names\n",
    "class_names = list(idx_to_class.values())\n",
    "\n",
    "# Print classification reports\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESNET50 CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(resnet_results['labels'], resnet_results['predictions'],\n",
    "                          target_names=class_names, digits=3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EFFICIENTNETB0 CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(efficientnet_results['labels'], efficientnet_results['predictions'],\n",
    "                          target_names=class_names, digits=3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CUSTOM CNN-20 CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(model_20_results['labels'], model_20_results['predictions'],\n",
    "                          target_names=class_names, digits=3))\n",
    "\n",
    "# Plot confusion matrices\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, class_names):\n",
    "    \"\"\"Plot confusion matrix heatmap\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} - Confusion Matrix', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=15)\n",
    "    plt.xlabel('Predicted Label', fontsize=15)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot confusion matrices for all three models\n",
    "plot_confusion_matrix(resnet_results['labels'], resnet_results['predictions'],\n",
    "                     'ResNet50', class_names)\n",
    "plot_confusion_matrix(efficientnet_results['labels'], efficientnet_results['predictions'],\n",
    "                     'EfficientNetB0', class_names)\n",
    "plot_confusion_matrix(model_20_results['labels'], model_20_results['predictions'],\n",
    "                     'Custom CNN-20', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7dab11508e0068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.204776600Z",
     "start_time": "2025-11-13T12:06:05.932707Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6.4 Cross-Validation (K-Fold)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "RUN_CV = True  # Set to True to run CV. Only set it to True if you need to run it, as it takes long time to do so.\n",
    "\n",
    "if RUN_CV:\n",
    "    N_SPLITS = 5\n",
    "    EPOCHS_PER_FOLD = 10\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"STARTING {N_SPLITS}-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Load full clean dataset\n",
    "    clean_dataset_full = torchvision.datasets.ImageFolder(root=CLEAN_DIR, transform=train_tf)\n",
    "    all_indices = np.arange(len(clean_dataset_full))\n",
    "\n",
    "    kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Store results for each fold\n",
    "    cv_results = {\n",
    "        'ResNet50': {'loss': [], 'accuracy': [], 'top3_acc': []},\n",
    "        'EfficientNetB0': {'loss': [], 'accuracy': [], 'top3_acc': []},\n",
    "        'Custom_CNN20': {'loss': [], 'accuracy': [], 'top3_acc': []}\n",
    "    }\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(all_indices)):\n",
    "        print(f\"\\n{'=' * 25} FOLD {fold + 1}/{N_SPLITS} {'=' * 25}\")\n",
    "\n",
    "        # Create data subsets for this fold\n",
    "        train_subset = torch.utils.data.Subset(clean_dataset_full, train_ids)\n",
    "\n",
    "        val_dataset_fold = torchvision.datasets.ImageFolder(root=CLEAN_DIR, transform=val_tf)\n",
    "        val_subset = torch.utils.data.Subset(val_dataset_fold, val_ids)\n",
    "\n",
    "        train_loader_fold = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                      num_workers=NUM_WORKERS, pin_memory=PIN)\n",
    "        val_loader_fold = DataLoader(val_subset, batch_size=BATCH_SIZE * 2, shuffle=False,\n",
    "                                    num_workers=NUM_WORKERS, pin_memory=PIN)\n",
    "\n",
    "        # Train ResNet50\n",
    "        print(\"\\nTraining ResNet50...\")\n",
    "        resnet_fold = build_resnet50_classifier(num_classes=len(idx_to_class))\n",
    "        resnet_fold, _ = train_model(resnet_fold, train_loader_fold, val_loader_fold,\n",
    "                                    epochs=EPOCHS_PER_FOLD, patience=3,\n",
    "                                    model_name=f\"resnet50_fold{fold+1}\")\n",
    "\n",
    "        # Evaluate ResNet50\n",
    "        resnet_fold_results = evaluate_model_pytorch(resnet_fold, val_loader_fold, device)\n",
    "        cv_results['ResNet50']['loss'].append(resnet_fold_results['loss'])\n",
    "        cv_results['ResNet50']['accuracy'].append(resnet_fold_results['accuracy'])\n",
    "        cv_results['ResNet50']['top3_acc'].append(resnet_fold_results['top_k_accuracy'])\n",
    "        print(f\"  ResNet50 Fold {fold + 1} - Val Acc: {resnet_fold_results['accuracy']:.2f}%\")\n",
    "\n",
    "        # Train EfficientNetB0\n",
    "        print(\"\\nTraining EfficientNetB0...\")\n",
    "        efficientnet_fold = build_efficientnet_classifier(num_classes=len(idx_to_class))\n",
    "        efficientnet_fold, _ = train_model(efficientnet_fold, train_loader_fold, val_loader_fold,\n",
    "                                          epochs=EPOCHS_PER_FOLD, patience=3,\n",
    "                                          model_name=f\"efficientnet_fold{fold+1}\")\n",
    "\n",
    "        # Evaluate EfficientNetB0\n",
    "        eff_fold_results = evaluate_model_pytorch(efficientnet_fold, val_loader_fold, device)\n",
    "        cv_results['EfficientNetB0']['loss'].append(eff_fold_results['loss'])\n",
    "        cv_results['EfficientNetB0']['accuracy'].append(eff_fold_results['accuracy'])\n",
    "        cv_results['EfficientNetB0']['top3_acc'].append(eff_fold_results['top_k_accuracy'])\n",
    "        print(f\"  EfficientNetB0 Fold {fold + 1} - Val Acc: {eff_fold_results['accuracy']:.2f}%\")\n",
    "        # Train Custom CNN-20\n",
    "        print(\"\\nTraining Custom CNN-20...\")\n",
    "        cnn20_fold = CNN20Model(num_classes=len(idx_to_class))\n",
    "        cnn20_fold, _ = train_model(cnn20_fold, train_loader_fold, val_loader_fold,\n",
    "                                   epochs=EPOCHS_PER_FOLD, patience=3,\n",
    "                                   model_name=f\"cnn20_fold{fold+1}\")\n",
    "\n",
    "        # Evaluate Custom CNN-20\n",
    "        cnn20_fold_results = evaluate_model_pytorch(cnn20_fold, val_loader_fold, device)\n",
    "        cv_results['Custom_CNN20']['loss'].append(cnn20_fold_results['loss'])\n",
    "        cv_results['Custom_CNN20']['accuracy'].append(cnn20_fold_results['accuracy'])\n",
    "        cv_results['Custom_CNN20']['top3_acc'].append(cnn20_fold_results['top_k_accuracy'])\n",
    "        print(f\"  Custom CNN-20 Fold {fold + 1} - Val Acc: {cnn20_fold_results['accuracy']:.2f}%\")\n",
    "\n",
    "    # Per-fold summary DataFrame\n",
    "    import pandas as pd\n",
    "    cv_summary = pd.DataFrame({\n",
    "        'Fold': [f'Fold {i+1}' for i in range(N_SPLITS)],\n",
    "        'ResNet50 Acc (%)': cv_results['ResNet50']['accuracy'],\n",
    "        'EfficientNetB0 Acc (%)': cv_results['EfficientNetB0']['accuracy'],\n",
    "        'CNN-20 Acc (%)': cv_results['Custom_CNN20']['accuracy'],\n",
    "        'ResNet50 Loss': cv_results['ResNet50']['loss'],\n",
    "        'EfficientNetB0 Loss': cv_results['EfficientNetB0']['loss'],\n",
    "        'CNN-20 Loss': cv_results['Custom_CNN20']['loss'],\n",
    "        'ResNet50 Top-3 Acc (%)': cv_results['ResNet50']['top3_acc'],\n",
    "        'EfficientNetB0 Top-3 Acc (%)': cv_results['EfficientNetB0']['top3_acc'],\n",
    "        'CNN-20 Top-3 Acc (%)': cv_results['Custom_CNN20']['top3_acc'],\n",
    "    })\n",
    "\n",
    "    print(\"\\nPer-Fold Results:\")\n",
    "    display(cv_summary.style.format({\n",
    "        'ResNet50 Acc (%)': '{:.2f}',\n",
    "        'EfficientNetB0 Acc (%)': '{:.2f}',\n",
    "        'CNN-20 Acc (%)': '{:.2f}',\n",
    "        'ResNet50 Loss': '{:.4f}',\n",
    "        'EfficientNetB0 Loss': '{:.4f}',\n",
    "        'CNN-20 Loss': '{:.4f}',\n",
    "        'ResNet50 Top-3 Acc (%)': '{:.2f}',\n",
    "        'EfficientNetB0 Top-3 Acc (%)': '{:.2f}',\n",
    "        'CNN-20 Top-3 Acc (%)': '{:.2f}',\n",
    "    }))\n",
    "\n",
    "    # Average results summary\n",
    "    avg_results = pd.DataFrame({\n",
    "        'Model': ['ResNet50', 'EfficientNetB0', 'Custom CNN-20'],\n",
    "        'Avg Accuracy (%)': [\n",
    "            np.mean(cv_results['ResNet50']['accuracy']),\n",
    "            np.mean(cv_results['EfficientNetB0']['accuracy']),\n",
    "            np.mean(cv_results['Custom_CNN20']['accuracy'])\n",
    "        ],\n",
    "        'Std Accuracy': [\n",
    "            np.std(cv_results['ResNet50']['accuracy']),\n",
    "            np.std(cv_results['EfficientNetB0']['accuracy']),\n",
    "            np.std(cv_results['Custom_CNN20']['accuracy'])\n",
    "        ],\n",
    "        'Avg Loss': [\n",
    "            np.mean(cv_results['ResNet50']['loss']),\n",
    "            np.mean(cv_results['EfficientNetB0']['loss']),\n",
    "            np.mean(cv_results['Custom_CNN20']['loss'])\n",
    "        ],\n",
    "        'Avg Top-3 Acc (%)': [\n",
    "            np.mean(cv_results['ResNet50']['top3_acc']),\n",
    "            np.mean(cv_results['EfficientNetB0']['top3_acc']),\n",
    "            np.mean(cv_results['Custom_CNN20']['top3_acc'])\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    print(\"\\nAverage Across All Folds:\")\n",
    "    display(avg_results.style.format({\n",
    "        'Avg Accuracy (%)': '{:.2f}',\n",
    "        'Std Accuracy': '{:.2f}',\n",
    "        'Avg Loss': '{:.4f}',\n",
    "        'Avg Top-3 Acc (%)': '{:.2f}'\n",
    "    }).hide(axis=\"index\"))\n",
    "\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Cross-Validation skipped (RUN_CV=False)\")\n",
    "    print(\"Set RUN_CV=True to run K-Fold Cross-Validation\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6a30e758fd554",
   "metadata": {},
   "source": [
    "#### 7. Export Notebook to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f1587ca76aa29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T06:16:36.204776600Z",
     "start_time": "2025-11-13T13:43:59.205547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export this notebook with all outputs to HTML for reporting\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "notebook_name = \"FirstDraft.ipynb\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_html = f\"PlantDisease_Training_Report_{timestamp}.html\"\n",
    "\n",
    "try:\n",
    "    # Use nbconvert to export\n",
    "    result = subprocess.run([\n",
    "    'jupyter', 'nbconvert',\n",
    "    '--to', 'html',\n",
    "    '--no-input',\n",
    "    '--no-prompt',\n",
    "    '--template', 'classic',\n",
    "    'FirstDraft.ipynb'\n",
    "    ], check=True)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"✓ NOTEBOOK EXPORTED SUCCESSFULLY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nHTML Report: {output_html}\")\n",
    "        print(f\"Location: {Path(output_html).absolute()}\")\n",
    "        print(\"\\nThis report includes:\")\n",
    "        print(\"  • Data cleaning statistics\")\n",
    "        print(\"  • Training curves for both models\")\n",
    "        print(\"  • Performance metrics and comparisons\")\n",
    "        print(\"  • Confusion matrices\")\n",
    "        print(\"  • Classification reports\")\n",
    "    else:\n",
    "        print(\"\\nError exporting notebook:\")\n",
    "        print(result.stderr)\n",
    "        print(\"\\nTry installing nbconvert: pip install nbconvert\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nJupyter nbconvert not found.\")\n",
    "    print(\"Install it with: pip install nbconvert\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\nAlternatively, export manually via: File > Download as > HTML\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS3000-25Fall",
   "language": "python",
   "name": "ds3000-25fall"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
